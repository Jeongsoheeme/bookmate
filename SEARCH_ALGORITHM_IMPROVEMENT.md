# 검색 알고리즘 개선 비교 문서

## 📋 개요

AI 검색 기능의 성능과 비용 효율성을 개선하기 위해 2단계 필터링 방식을 도입했습니다.

---

## 🔴 기존 방식 (개선 전)

### 처리 과정

```
1. 모든 이벤트를 DB에서 가져옴
   └─ 예: 10,000개의 이벤트 전체 조회

2. 모든 이벤트 정보를 JSON으로 변환
   └─ 각 이벤트의 제목, 설명, 장르, 장소 등 모든 정보 포함

3. LLM에게 모든 이벤트 정보 전달
   └─ 10,000개 이벤트 정보를 모두 LLM에게 보냄

4. LLM이 10,000개 중에서 가장 관련성 높은 이벤트 선택
```

### 코드 예시 (개선 전)

```python
# 1. 모든 이벤트를 가져와서 AI에게 전달할 컨텍스트 생성
all_events = db.query(Event).all()  # 10,000개 전체 조회

# 이벤트 정보를 JSON 형식으로 정리
events_context = []
for event in all_events:  # 10,000개 모두 처리
    events_context.append({
        "id": event.id,
        "title": event.title,
        "description": event.description or "",
        "genre": event.genre.value if event.genre else None,
        "sub_genre": event.sub_genre.value if event.sub_genre else None,
        "location": event.location or "",
    })

# 2. OpenAI를 사용하여 사용자 쿼리 분석 및 가장 관련성 높은 이벤트 찾기
user_prompt = f"""사용자 검색어: "{request.query}"

다음은 현재 등록된 모든 이벤트 목록입니다:
{json.dumps(events_context, ensure_ascii=False, indent=2)}  # 10,000개 모두 전달

위 이벤트 목록 중에서 사용자 검색어와 가장 관련성 높은 이벤트를 찾아주세요."""
```

### 문제점

| 항목 | 설명 |
|------|------|
| **LLM API 비용** | 모든 이벤트 정보를 전달하므로 토큰 수가 매우 많음 (예: 10,000개 × 평균 200토큰 = 2,000,000토큰) |
| **응답 시간** | LLM이 많은 데이터를 처리해야 하므로 응답 시간이 길어짐 (예: 5-10초) |
| **확장성** | 이벤트가 많아질수록 (10,000개 → 100,000개) 더 느려지고 비용이 증가 |
| **메모리 사용** | 모든 이벤트를 메모리에 로드하므로 메모리 사용량 증가 |

### 예상 비용 (이벤트 10,000개 기준)

- **입력 토큰**: 약 2,000,000 토큰
- **출력 토큰**: 약 100 토큰
- **비용** (gpt-4o-mini 기준): 약 $0.15 per request
- **응답 시간**: 5-10초

---

## 🟢 개선된 방식 (개선 후)

### 처리 과정

```
1. 사용자 쿼리에서 키워드 추출 (LLM 사용, 가벼운 작업)
   └─ 예: "조용필 콘서트 예매해줘" → ["조용필"]
   └─ LLM 호출 1회 (가벼운 작업, 약 50-100 토큰)

2. SQL 쿼리로 1차 필터링 (DB에서 빠르게)
   └─ 제목, 설명, 장르, 장소에서 키워드 검색
   └─ 예: 10,000개 → 5개로 축소
   └─ DB 인덱스 활용으로 매우 빠름 (약 0.01초)

3. 필터링된 결과만 LLM에게 전달하여 최종 선택
   └─ 5개 이벤트 정보만 LLM에게 보냄
   └─ LLM 호출 1회 (적은 데이터, 약 200-500 토큰)
```

### 코드 예시 (개선 후)

```python
# STEP 1: 키워드 추출 (LLM 사용)
keywords = await extract_keywords_from_query(request.query)
# 예: "조용필 콘서트 예매해줘" → ["조용필"]

# STEP 2: SQL 쿼리로 1차 필터링 (DB에서 빠르게)
filtered_events = filter_events_by_keywords(db, keywords, limit=50)
# 예: 10,000개 → 5개로 축소

# STEP 3: 필터링된 결과만 LLM에게 전달하여 최종 선택
events_context = []
for event in filtered_events:  # 5개만 처리
    events_context.append({
        "id": event.id,
        "title": event.title,
        "description": event.description or "",
        "genre": event.genre.value if event.genre else None,
        "sub_genre": event.sub_genre.value if event.sub_genre else None,
        "location": event.location or "",
    })

user_prompt = f"""사용자 검색어: "{request.query}"

추출된 키워드: {', '.join(keywords)}

다음은 키워드 기반으로 필터링된 이벤트 목록입니다 (총 {len(events_context)}개):
{json.dumps(events_context, ensure_ascii=False, indent=2)}  # 5개만 전달

위 이벤트 목록 중에서 사용자 검색어와 가장 관련성 높은 이벤트를 찾아주세요."""
```

### 장점

| 항목 | 설명 |
|------|------|
| **LLM API 비용** | 필터링된 결과만 전달하므로 토큰 수가 대폭 감소 (예: 5개 × 평균 200토큰 = 1,000토큰) |
| **응답 시간** | LLM이 적은 데이터를 처리하므로 응답 시간이 단축 (예: 1-2초) |
| **확장성** | 이벤트가 많아져도 (10,000개 → 100,000개) SQL 필터링으로 먼저 축소하므로 성능 유지 |
| **메모리 사용** | 필터링된 결과만 메모리에 로드하므로 메모리 사용량 감소 |

### 예상 비용 (이벤트 10,000개 기준)

- **키워드 추출**:
  - 입력 토큰: 약 100 토큰
  - 출력 토큰: 약 50 토큰
  - 비용: 약 $0.00001 per request

- **최종 선택**:
  - 입력 토큰: 약 1,000 토큰 (5개 이벤트)
  - 출력 토큰: 약 100 토큰
  - 비용: 약 $0.0005 per request

- **총 비용**: 약 $0.00051 per request
- **응답 시간**: 1-2초

---

## 📊 성능 비교

### 이벤트 10,000개 기준

| 항목 | 기존 방식 | 개선된 방식 | 개선율 |
|------|----------|-----------|--------|
| **LLM 입력 토큰** | ~2,000,000 | ~1,100 | **99.9% 감소** |
| **API 호출 비용** | ~$0.15 | ~$0.00051 | **99.7% 감소** |
| **응답 시간** | 5-10초 | 1-2초 | **80% 단축** |
| **메모리 사용** | 높음 | 낮음 | **대폭 감소** |

### 이벤트 100,000개 기준

| 항목 | 기존 방식 | 개선된 방식 | 개선율 |
|------|----------|-----------|--------|
| **LLM 입력 토큰** | ~20,000,000 | ~1,100 | **99.99% 감소** |
| **API 호출 비용** | ~$1.50 | ~$0.00051 | **99.97% 감소** |
| **응답 시간** | 30-60초 | 1-2초 | **95% 단축** |
| **메모리 사용** | 매우 높음 | 낮음 | **대폭 감소** |

---

## 🔍 핵심 개선 사항

### 1. 키워드 추출 함수 (`extract_keywords_from_query`)

```python
async def extract_keywords_from_query(query: str) -> List[str]:
    """
    사용자 쿼리에서 검색 키워드를 추출합니다.
    LLM을 사용하여 의미 있는 키워드를 추출합니다.
    
    예시:
    - "조용필 콘서트 예매해줘" → ["조용필"]
    - "서울에서 열리는 뮤지컬 찾아줘" → ["서울", "뮤지컬"]
    """
```

**특징:**
- LLM을 사용하지만 가벼운 작업 (약 50-100 토큰)
- 불필요한 단어 제거 (예매해줘, 찾아줘 등)
- 폴백 메커니즘 제공 (LLM 실패 시 간단한 키워드 추출)

### 2. SQL 필터링 함수 (`filter_events_by_keywords`)

```python
def filter_events_by_keywords(db: Session, keywords: List[str], limit: int = 50) -> List[Event]:
    """
    키워드 기반으로 이벤트를 SQL 쿼리로 필터링합니다.
    제목, 설명, 장르, 세부장르, 장소에서 키워드를 검색합니다.
    """
```

**특징:**
- DB 인덱스 활용으로 매우 빠름
- 제목, 설명, 장르, 세부장르, 장소에서 검색
- 결과 제한 (최대 50개)으로 LLM 처리 비용 최소화

### 3. 2단계 필터링 프로세스

```
사용자 쿼리
    ↓
[STEP 1] 키워드 추출 (LLM)
    ↓
[STEP 2] SQL 필터링 (DB)
    ↓
[STEP 3] 최종 선택 (LLM)
    ↓
결과 반환
```

---

## 💡 사용 예시

### 예시 1: "조용필 콘서트 예매해줘"

**기존 방식:**
1. 10,000개 이벤트 모두 조회
2. 10,000개 정보를 LLM에게 전달
3. LLM이 10,000개 중에서 선택
4. 비용: ~$0.15, 시간: 5-10초

**개선된 방식:**
1. 키워드 추출: "조용필"
2. SQL 필터링: 제목/설명에 "조용필" 포함된 이벤트만 조회 (10,000개 → 2개)
3. 2개 정보만 LLM에게 전달하여 선택
4. 비용: ~$0.00051, 시간: 1-2초

### 예시 2: "서울에서 열리는 뮤지컬 찾아줘"

**기존 방식:**
1. 10,000개 이벤트 모두 조회
2. 10,000개 정보를 LLM에게 전달
3. LLM이 10,000개 중에서 선택
4. 비용: ~$0.15, 시간: 5-10초

**개선된 방식:**
1. 키워드 추출: ["서울", "뮤지컬"]
2. SQL 필터링: 장소에 "서울" 포함 + 장르가 "뮤지컬"인 이벤트만 조회 (10,000개 → 15개)
3. 15개 정보만 LLM에게 전달하여 선택
4. 비용: ~$0.00051, 시간: 1-2초

---

## 🎯 결론

개선된 방식은 다음과 같은 이점을 제공합니다:

1. **비용 효율성**: LLM API 호출 비용이 99% 이상 감소
2. **성능 향상**: 응답 시간이 80-95% 단축
3. **확장성**: 이벤트가 많아져도 성능 유지
4. **메모리 효율성**: 메모리 사용량 대폭 감소

이러한 개선으로 사용자 경험이 향상되고, 운영 비용이 크게 절감됩니다.
